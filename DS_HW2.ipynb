{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 2\n",
    "\n",
    "## Lili Tan - lt2846\n",
    "\n",
    "### Due: Fri Mar 11th @ 11:59pm ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will be performing model evaluation, model selection and hyperparameter tuning in both a regression and classification setting.\n",
    "\n",
    "We will be working with a small set of home sales data as we might see on a real-estate website.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Follow the comments below and fill in the blanks (\\_\\_\\_\\_) to complete.\n",
    "- Please **'Restart and Run All'** prior to submission.\n",
    "- **Save pdf in Landscape** and **check that all of your code is shown** in the submission.\n",
    "- When submitting in Gradescope, be sure to **select which page corresponds to which question.**\n",
    "\n",
    "Out of 50 points total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (2pts) Set up our environment with common libraries and plot settings.\n",
    "#    Note: generally we would do all of our imports here but some imports\n",
    "#    have been left till later where they are used.\n",
    "\n",
    "# Import numpy as np, pandas as pd, matplotlib.pyplot as plt and seaborn as sns\n",
    "# Note: use as many lines of code as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the seaborn style to 'darkgrid'\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Execute the matplotlib magic function to ensure plots are displayed inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 1 we will try to predict a real value home sale price using several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. (4pts) Load and prepare our data.\n",
    "\n",
    "# Read in the csv file ../data/house_sales_subset.csv using pandas read_csv() with default parameter settings\n",
    "df = pd.read_csv('../data/house_sales_subset.csv')\n",
    "\n",
    "# Create a dataframe X which contains these 3 columns from df:\n",
    "#  'SqFtTotLiving_x1000','SqFtLot_x1000','Bedrooms'\n",
    "X = df[['SqFtTotLiving_x1000','SqFtLot_x1000','Bedrooms']]\n",
    "\n",
    "# Create a series y_r which contains only the column AdjSalePrice_x100000\n",
    "#    Note: the '_r' is for our regression target\n",
    "y_r = df['AdjSalePrice_x100000']\n",
    "\n",
    "# Check that X and y_r is the correct shape\n",
    "assert X.shape == (1000,3)\n",
    "assert y_r.shape == (1000,)\n",
    "\n",
    "# To confirm that all features of X are similar in scale display the .describe() of X\n",
    "X.describe()\n",
    "\n",
    "# To get a sense of the distribution of the target, plot a histogram of y_r using sns.histplot()\n",
    "sns.histplot(x=y_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of data in test set: 0.20\n"
     ]
    }
   ],
   "source": [
    "# 3. (3pts) Create a held-aside set\n",
    "\n",
    "# Import train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y_r into 80% train and 20% test using train_test_split\n",
    "#   Use random_state=123 for grading consistency.\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X,y_r,train_size=.8,random_state=123)\n",
    "\n",
    "# Print out the the length of y_test_r divided by the length y_r  to confirm our test set size.\n",
    "print(f'proportion of data in test set: {len(y_test_r)/len(y_r):0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Baseline Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy training set R^2: 0.00\n"
     ]
    }
   ],
   "source": [
    "# 4. (3pts) Create a DummyRegressor and fit on the training set.\n",
    "\n",
    "# Import the DummyRegressor model from sklearn \n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Instantiate a DummyRegessor model with strategy=\"mean\" \n",
    "dummy_r = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Train the DummyRegressor on the regression training set\n",
    "dummy_r.fit(X_train_r,y_train_r)\n",
    "\n",
    "# Calculate and print the training set R^2 score of the DummyRegressor\n",
    "dummy_r_training_r2 = dummy_r.score(X_train_r,y_train_r)\n",
    "\n",
    "print(f'dummy training set R^2: {dummy_r_training_r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Linear Regression and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr training set R^2: 0.53\n"
     ]
    }
   ],
   "source": [
    "# 5. (4pts) Train a Linear Regression model and calculate training set R^2.\n",
    "\n",
    "# Import the LinearRegression model from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate a LinearRegression model with default arguments and fit on the training set\n",
    "lr = LinearRegression().fit(X_train_r,y_train_r)\n",
    "\n",
    "# Calculate and print the training set R^2 of the LinearRegression model\n",
    "lr_training_r2 = lr.score(X_train_r,y_train_r)\n",
    "\n",
    "print(f'lr training set R^2: {lr_training_r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48, 0.58, 0.5 , 0.44, 0.58])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. (2pts) Use 5-fold Cross Validation to get a sense of variation \n",
    "#    of Liner Regression R^2 performance on the training set.\n",
    "\n",
    "# Import cross_val_score from sklearn.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Generate 5-fold cross-validation R^2 scores \n",
    "#    for a LinearRegression model with default arguments \n",
    "#    on the training set\n",
    "lr_cv_scores = cross_val_score(LinearRegression(),X_train_r,y_train_r,cv=5)\n",
    "\n",
    "# Print out the R^2 scores found by cross_val_score\n",
    "np.round(lr_cv_scores,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr mean cv r2: 0.52 +- 0.11\n"
     ]
    }
   ],
   "source": [
    "# 7. (1pts) Calculate mean cv R^2 score +- 2 std. deviations\n",
    "\n",
    "# Calculate the mean cross validation score using the scores created above\n",
    "lr_cv_mean = np.mean(lr_cv_scores)\n",
    "\n",
    "# Calculate 2 standard deviations of the cross validation scores\n",
    "lr_cv_2std = 2*np.std(lr_cv_scores)\n",
    "\n",
    "# Print out the mean R^2 +- 2 standard variations for the LinearRegression model\n",
    "print(f'lr mean cv r2: {lr_cv_mean:.2f} +- {lr_cv_2std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy test R2 : -0.01\n",
      "   lr test R2 :  0.47\n"
     ]
    }
   ],
   "source": [
    "# 8. (2pts) Evaluate performance of our trained DummyRegressor and LinearRegression model on the test set.\n",
    "\n",
    "# Calculate R^2 on the test set using the previously trained models\n",
    "dummy_r_test_r2 = dummy_r.score(X_test_r,y_test_r)\n",
    "\n",
    "lr_test_r2 = lr.score(X_test_r,y_test_r)\n",
    "\n",
    "print(f'dummy test R2 : {dummy_r_test_r2: .2f}')\n",
    "print(f'   lr test R2 : {lr_test_r2: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build several models to classify low vs. high adjusted sales price, creating a validation curve and performing grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reuse the same dataset, we'll first create a binary target for \n",
    "#    classification by thresholding at the mean of our AdjSalePrice\n",
    "\n",
    "# The classes are:\n",
    "#    Low AdjSalePrice  = 0\n",
    "#    High AdjSalePrice = 1\n",
    "\n",
    "y_c = (df.AdjSalePrice_x100000 > df.AdjSalePrice_x100000.mean()).astype(int)\n",
    "\n",
    "# Print out the unique labels and note it's 0,1 or binary classification\n",
    "y_c.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 Create a Held-Aside Aet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of low values: 0.59\n"
     ]
    }
   ],
   "source": [
    "# 9. (3pts) Create a training and test/held-aside set\n",
    "\n",
    "# Split into 80% train and 20% test using train_test_split \n",
    "#    Use the new y_c target and the same X we used for regression\n",
    "#    Stratify according to y_c so class proportions are the same in train and test\n",
    "#    Use random_state=123 for reproducibility\n",
    "#    Save the result into the variables X_train_c,X_test_c,y_train_c,y_test_c\n",
    "X_train_c,X_test_c,y_train_c,y_test_c = train_test_split(X,y_c,train_size=.8,stratify=y_c,random_state=123)\n",
    "\n",
    "# Print out the proportion of Low values (label of 0) in y_c\n",
    "print(f'proportion of low values: {sum(y_c==0)/len(y_c):0.2f}')\n",
    "\n",
    "# Assert that train and test have similar class proportions.\n",
    "# Find the proportion of Low (0) values in both y_train_c and y_test_c and \n",
    "#    assert that the absolute difference of these proportions is less than .01\n",
    "assert abs((sum(y_train_c==0)/len(y_train_c))-(sum(y_test_c==0)/len(y_test_c))) < .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 Measure baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy training set accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "# 10. (2pts)  Create a Dummy Classifier and confirm the expected performance on the training set.\n",
    "\n",
    "# Import DummyClassifier from sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Instantiate and a DummyClassifier with strategy=\"most_frequent\" and fit on the the training set\n",
    "dummy_c = DummyClassifier(strategy='most_frequent').fit(X_train_c,y_train_c)\n",
    "\n",
    "# Print the trained DummyClassifier accuracy on the training set.\n",
    "# It should match the proportion of low values we saw above.\n",
    "print(f'dummy training set accuracy: {dummy_c.score(X_train_c,y_train_c):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3  Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logr mean cv accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# 11. (3pts) It's good practice to start with a \"simple\" model.\n",
    "#     Train and calculate 5-fold cv training set accuracy for a Logistic Regression Classifier.\n",
    "\n",
    "# Import LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Generate 5-fold cross validation accuracy on the training set\n",
    "#    using LogisticRegression with default hyperparameters\n",
    "#    store as logr_cvscores\n",
    "logr_cvscores = cross_val_score(LogisticRegression(),X_train_c,y_train_c,cv=5)\n",
    "\n",
    "# Print out the mean cv accuracy for the LogisticRegression model\n",
    "print(f'logr mean cv accuracy: {np.mean(logr_cvscores):0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4 GradientBoosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc mean cv accuracy: 0.80 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "# 12. (4pts) Now let's try a more complex model.\n",
    "#     Train and calculate 5-fold cv accuracy \n",
    "#     for a GradientBoosting model using the training set.\n",
    "\n",
    "# Import the GradientBoostingClassifier model from sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Calculate 5-fold cv training set accuracy scores for a GradientBoostingClassifier\n",
    "#   with 50 trees and max_depth=2\n",
    "#   To speed up training also set n_jobs=-1 in the cross_val_score (use one core for each fold)\n",
    "gbc_cv_scores = cross_val_score(GradientBoostingClassifier(n_estimators=50,max_depth=2),X_train_c,y_train_c,\n",
    "                                cv=5,n_jobs=-1)\n",
    " \n",
    "# Calculate mean cv accuracy\n",
    "gbc_cv_mean = np.mean(gbc_cv_scores)\n",
    "\n",
    "# Calculate 2 standard deviations for the cv scores\n",
    "gbc_cv_2std = 2*np.std(gbc_cv_scores)\n",
    "\n",
    "print(f'gbc mean cv accuracy: {gbc_cv_mean:.2f} +- {gbc_cv_2std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.5 GradientBoosting and Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>max_depth</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_train_scores</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_scores</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "max_depth            1     2     3     5     10\n",
       "mean_train_scores  0.81  0.84  0.87  0.95  0.99\n",
       "mean_test_scores   0.79  0.81  0.81  0.79  0.77"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13. (5pts) Let's investigate how the depth of trees (max_depth) affects performance.\n",
    "#     Generate a validation curve for tree depths in the GradientBoosting model.\n",
    "\n",
    "# Import the validation_curve function from sklearn\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# In the GradientBoostingClassifier model, the depth of trees is set via max_depth\n",
    "# Here we'll try the depths 1,2,3,5,10\n",
    "depths = [1,2,3,5,10]\n",
    "\n",
    "# Generate the train_scores and test_scores for max_depth at different max_depths\n",
    "#   Use the validation_curve function\n",
    "#   Use a GradientBoostingClassiier with 50 trees\n",
    "#   Use our training set X_train_c, y_train_c\n",
    "#   Use the 'max_depth' parameter\n",
    "#   Use the depths list created above as the parameter range\n",
    "#   Use 3-fold cross validation (reducing to 3 to speed things up)\n",
    "#   Use accuracy as the scoring metric\n",
    "#   Store the results in train_scores,test_scores\n",
    "train_scores,test_scores = validation_curve(GradientBoostingClassifier(n_estimators=50),\n",
    "                                            X_train_c, y_train_c, \n",
    "                                            param_name='max_depth', \n",
    "                                            param_range=depths, \n",
    "                                            cv=3,\n",
    "                                            scoring='accuracy')\n",
    "\n",
    "# train_scores and test_scores each contain a 2-D array of values\n",
    "#   For each depth (rows) there are 3 scores (columns), one for each fold\n",
    "#   Take the mean for each depth across folds (columns, axis=1) \n",
    "#      and store in mean_train_scores and mean_test_scores\n",
    "mean_train_scores = np.mean(train_scores,axis=1)\n",
    "mean_test_scores = np.mean(test_scores,axis=1)\n",
    "\n",
    "# We should get 10 values between 0 and 1\n",
    "# Note that as depth increases, both train and test accuracy go up and then begin to diverge\n",
    "pd.DataFrame([mean_train_scores.round(2),mean_test_scores.round(2)],\n",
    "             columns=pd.Series(depths,name='max_depth'),\n",
    "             index=['mean_train_scores','mean_test_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 14. (4pts) Plot the validation curve\n",
    "\n",
    "# Plot mean_train_scores and mean_test_scores on the same plot\n",
    "#    create an axis to plot on using subplots, with figsize=(6,4)\n",
    "#    plot two lines using ax.plot()\n",
    "#      each with \"depths\" on the x-axis\n",
    "#      one for mean_train_scores on the y-axis with label \"train\"\n",
    "#      one for mean_test_scores on the y-axis with label \"test\"\n",
    "#    add a legend using ax.legend()\n",
    "#    label the x-axis as \"max_depth\" and the y-axis as \"mean accuracy\"\n",
    "# Note: use as many lines of code as necessary\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,4))\n",
    "ax.plot(depths, mean_train_scores, 'o-', color='b',label='train');\n",
    "ax.plot(depths, mean_test_scores, 'o-', color='r', label='test'); \n",
    "ax.set_xlabel('max_depth'), ax.set_ylabel('mean accuracy'); \n",
    "ax.set_title('Validation Curve for GradientBoostingClassifier'); \n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.6 GradientBoosting and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc best hyperparams      : {'max_depth': 3, 'n_estimators': 50}\n",
      "gbc best mean cv accuracy : 0.81\n"
     ]
    }
   ],
   "source": [
    "# 15. (4pts) Above we're looking at tuning a single hyperparameter (max_depth).\n",
    "#     Now let's tune two hyperparameters at the same time.\n",
    "#     Perform 3-fold cross validated grid search over number of trees and tree depth.\n",
    "\n",
    "# Import GridSearchCV from sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the grid of parameters to test\n",
    "#   The parameter settings to try are \n",
    "#   'n_estimators':[10,50,100,200],'max_depth':[1,2,3,5,10]\n",
    "params = {'n_estimators':[10,50,100,200], 'max_depth':[1,2,3,5,10]}\n",
    "\n",
    "# Instantiate and fit GridSearchCV on the classification training set\n",
    "#   Use GradientBoostingClassifier with default arguments \n",
    "#   Use 3-folds\n",
    "#   Use default scoring (accuracy)\n",
    "#   Use refit=True (default) so the model is retrained on the entire training set\n",
    "#   Set n_jobs=-1 to use all cores\n",
    "gbc_gscv = GridSearchCV(GradientBoostingClassifier(),\n",
    "                        param_grid=params,\n",
    "                        cv=3,\n",
    "                        scoring='accuracy',\n",
    "                        refit=True,\n",
    "                        n_jobs=-1).fit(X_train_c,y_train_c)\n",
    "\n",
    "# Print out the best the best hyperparameter setting found (best_params_) \n",
    "#    and the mean accuracy they produced (best_score_)\n",
    "print(f'gbc best hyperparams      : {gbc_gscv.best_params_}')\n",
    "print(f'gbc best mean cv accuracy : {gbc_gscv.best_score_:.2f}')\n",
    "\n",
    "# Note that you may get different answers on different runs due to \n",
    "#   the random cv splits used at each grid point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.7 Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model found: LogisticRegression\n",
      "logr test acc : 0.82\n",
      "gbc  test acc : 0.84\n"
     ]
    }
   ],
   "source": [
    "# 16. (4pts) Evaluate the best model on the test set\n",
    "\n",
    "# Which of our models has the highest training set cv accuracy?\n",
    "#   (GradientBoostingClassifier or LogisticRegression?)\n",
    "print('best model found: LogisticRegression')\n",
    "\n",
    "# To see how each of our models would generalize to new data,\n",
    "#     calculate the **test set** accuracy for each of our trained models\n",
    "\n",
    "# First, instantiate and train a new LogisticRegression model with default settings on the training set.\n",
    "# Note that, while we did train a LogisticRegression model several times when \n",
    "#  calculating the cross-validation accuracy, we never trained it on the full training set\n",
    "logr = LogisticRegression().fit(X_train_c,y_train_c)\n",
    "\n",
    "# Find the test set accuracy of both of our trained models\n",
    "# Recall that since we used refit=True when doing grid search\n",
    "#  on the GradientBoostingClassifier, we can use gbc_gscv.score() without retraining\n",
    "logr_test_acc = logr.score(X_test_c,y_test_c)\n",
    "gbc_test_acc = gbc_gscv.score(X_test_c,y_test_c)\n",
    "\n",
    "print(f'logr test acc : {logr_test_acc:.2f}')\n",
    "print(f'gbc  test acc : {gbc_test_acc:.2f}')\n",
    "\n",
    "# TO THINK ABOUT, BUT DON'T NEED TO ANSWER:\n",
    "# Did the model we chose have the best test set performance?\n",
    "# Is it guaranteed that the model with the best cv scores on the training set has the best test set score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
